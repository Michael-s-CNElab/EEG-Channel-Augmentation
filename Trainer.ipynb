{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLT Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed EEG segments: 888, skipped (NaN/Inf): 0\n",
      "Processed EEG segments: 225, skipped (NaN/Inf): 0\n",
      "888\n",
      "225\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './Dataloader')\n",
    "from SLT_dataloader import EEGROIDataset, SignalDataCollator, EEGROI_fft_Dataset, EEGROI_Power_Dataset,CSVEEGDataset\n",
    "\n",
    "# Usage example\n",
    "roi_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\"\n",
    "eeg_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\"\n",
    "group_file = \"./Dataloader/subject_groups.json\"\n",
    "# segment_file = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\RO\\I\\Desikan_Kilianny_with_3pca\\\\roi_removal_segment.txt\"\n",
    "\n",
    "# Create dataset\n",
    "#train_dataset = EEGROI_fft_Dataset(roi_folder, eeg_folder, group_file, \"train_dataset\" )\n",
    "#print(f\"\\n\\n================================================\\n\")\n",
    "#print(f\"Total dataset size: {len(train_dataset)}\")\n",
    "#print(f\"\\n================================================\\n\\n\")\n",
    "# Create dataset\n",
    "#test_dataset = EEGROI_fft_Dataset(roi_folder, eeg_folder, group_file, \"test_eval\")\n",
    "#print(f\"\\n================================================\\n\")\n",
    "#print(f\"Total eval dataset size: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "csveeg_folder=\"G:\\\\共用雲端硬碟\\\\CNElab_專題111_ArtifactRemoval\\\\6.Opendataset\\\\0.Resting(train)\\\\2.rawdata\\\\test\\\\Brain\"\n",
    "\n",
    "train_dataset = CSVEEGDataset(eeg_folder=csveeg_folder, group_name=\"train_dataset\")\n",
    "test_dataset = CSVEEGDataset(eeg_folder=csveeg_folder, group_name=\"test_eval\")\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './Dataloader')\n",
    "from SLT_dataloader import EEGROIDataset, SignalDataCollator, EEGROI_fft_Dataset, EEGROI_Power_Dataset\n",
    "\n",
    "train_path = \"G:\\\\共用雲端硬碟\\CNElab_陳昱祺\\\\source localization\\\\simulate_data\\\\training_data\\\\\"    # dataset_seedsource_5000_1000000.0_20250402_065238\n",
    "test_path =   \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\\\\\"\n",
    "group_file = \"./Dataloader/subject_groups.json\"\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = EEGROI_Power_Dataset(train_path)\n",
    "print(f\"\\n\\n================================================\\n\")\n",
    "print(f\"Total dataset size: {len(train_dataset)}\")\n",
    "print(f\"\\n================================================\\n\\n\")\n",
    "# Create dataset\n",
    "test_dataset = EEGROI_fft_Dataset(test_path, test_path, group_file, \"train_dataset\")\n",
    "print(f\"\\n================================================\\n\")\n",
    "print(f\"Total eval dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Power shape: torch.Size([20000, 30, 100])\n",
      "Source Power shape: torch.Size([20000, 204, 100])\n",
      "EEG Power shape: torch.Size([20000, 30, 100])\n",
      "Source Power shape: torch.Size([20000, 204, 100])\n",
      "EEG Power shape: torch.Size([20000, 30, 100])\n",
      "Source Power shape: torch.Size([20000, 204, 100])\n",
      "EEG Power shape: torch.Size([20000, 30, 100])\n",
      "Source Power shape: torch.Size([20000, 204, 100])\n",
      "EEG Power shape: torch.Size([20000, 30, 100])\n",
      "Source Power shape: torch.Size([20000, 204, 100])\n",
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166']\n",
      "EEG Power shape: torch.Size([30, 100])\n",
      "Source Power shape: torch.Size([204, 100])\n",
      "\n",
      "\n",
      "================================================\n",
      "\n",
      "Total dataset size: 123950\n",
      "\n",
      "================================================\n",
      "\n",
      "\n",
      "['167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250']\n",
      "EEG Power shape: torch.Size([30, 100])\n",
      "Source Power shape: torch.Size([204, 100])\n",
      "EEG Power shape: torch.Size([14000, 30, 100])\n",
      "Source Power shape: torch.Size([14000, 204, 100])\n",
      "\n",
      "================================================\n",
      "\n",
      "Total eval dataset size: 35932\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './Dataloader')\n",
    "from SLT_dataloader import EEGROIDataset, SignalDataCollator, EEGROI_fft_Dataset, EEGROI_Power_Dataset, EEGROI_Merge_Dataset\n",
    "\n",
    "data_path_1 = \"C:\\\\Users\\\\user\\\\Desktop\\\\Source Localization\\\\Source-Localization-Simulation\\\\simulate_data\\\\dataset_seedsource_100tp1000_2000_10_20250428_174623\\\\\"\n",
    "data_path_2 = \"C:\\\\Users\\\\user\\\\Desktop\\\\Source Localization\\\\Source-Localization-Simulation\\\\simulate_data\\\\dataset_seedsource_100to1000_2000_1000000.0_20250428_174549\\\\\"\n",
    "data_path_3 = \"C:\\\\Users\\\\user\\\\Desktop\\\\Source Localization\\\\Source-Localization-Simulation\\\\simulate_data\\\\dataset_seedsource_100to1000_2000_1_20250428_174640\\\\\"\n",
    "data_path_4 = \"C:\\\\Users\\\\user\\\\Desktop\\\\Source Localization\\\\Source-Localization-Simulation\\\\simulate_data\\\\dataset_seedsource_2to100_2000_10_20250428_201233\\\\\"\n",
    "data_path_5 = \"C:\\\\Users\\\\user\\\\Desktop\\\\Source Localization\\\\Source-Localization-Simulation\\\\simulate_data\\\\dataset_seedsource_2to100_2000_1000000.0_20250428_201134\\\\\"\n",
    "test_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Source Localization\\\\Desikan_Kilianny_with_3pca\\\\\"\n",
    "group_file = \"./Dataloader/subject_groups.json\"\n",
    "\n",
    "dataset_1 = EEGROI_Power_Dataset(data_path_1)\n",
    "dataset_2 = EEGROI_Power_Dataset(data_path_2)\n",
    "dataset_3 = EEGROI_Power_Dataset(data_path_3)\n",
    "dataset_4 = EEGROI_Power_Dataset(data_path_2)\n",
    "dataset_5 = EEGROI_Power_Dataset(data_path_3)\n",
    "dataset_6 = EEGROI_fft_Dataset(test_path, test_path, group_file, \"train_dataset\")\n",
    "\n",
    "merge_dataset = EEGROI_Merge_Dataset([dataset_1, dataset_2, dataset_3, dataset_4, dataset_5, dataset_6])\n",
    "train_data_len = len(merge_dataset)\n",
    "print(f\"\\n\\n================================================\\n\")\n",
    "print(f\"Total dataset size: {train_data_len}\")\n",
    "print(f\"\\n================================================\\n\\n\")\n",
    "\n",
    "test_dataset_1 = EEGROI_fft_Dataset(test_path, test_path, group_file, \"test_dataset_temp\")\n",
    "test_data_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\Source Localization\\\\Source-Localization-Simulation\\\\simulate_data\\\\dataset_seedsource_2to100_2000_1_20250429_144003\\\\\"\n",
    "test_dataset_2 = EEGROI_Power_Dataset(test_data_path)\n",
    "merge_eval_dataset = EEGROI_Merge_Dataset([test_dataset_1, test_dataset_2])\n",
    "test_data_len = len(merge_eval_dataset)\n",
    "print(f\"\\n================================================\\n\")\n",
    "print(f\"Total eval dataset size: {test_data_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11100' max='11100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11100/11100 12:04:19, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.826300</td>\n",
       "      <td>0.872212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.695200</td>\n",
       "      <td>0.792746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.557000</td>\n",
       "      <td>0.766919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.516500</td>\n",
       "      <td>0.696652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.465400</td>\n",
       "      <td>0.623360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0.420300</td>\n",
       "      <td>0.654069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>0.566700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.550858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>0.367600</td>\n",
       "      <td>0.482540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.341300</td>\n",
       "      <td>0.523265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>407</td>\n",
       "      <td>0.303100</td>\n",
       "      <td>0.423806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444</td>\n",
       "      <td>0.304400</td>\n",
       "      <td>0.420345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>481</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>0.370736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>518</td>\n",
       "      <td>0.306200</td>\n",
       "      <td>0.437969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>0.284500</td>\n",
       "      <td>0.352084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>592</td>\n",
       "      <td>0.279700</td>\n",
       "      <td>0.351552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629</td>\n",
       "      <td>0.282700</td>\n",
       "      <td>0.351261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>666</td>\n",
       "      <td>0.288900</td>\n",
       "      <td>0.350541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>703</td>\n",
       "      <td>0.249500</td>\n",
       "      <td>0.315073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.253800</td>\n",
       "      <td>0.320471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>0.256300</td>\n",
       "      <td>0.301298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>814</td>\n",
       "      <td>0.237400</td>\n",
       "      <td>0.305090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851</td>\n",
       "      <td>0.255100</td>\n",
       "      <td>0.300499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>0.221600</td>\n",
       "      <td>0.288764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>0.237800</td>\n",
       "      <td>0.286472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>962</td>\n",
       "      <td>0.188900</td>\n",
       "      <td>0.277045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>0.256415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1036</td>\n",
       "      <td>0.214200</td>\n",
       "      <td>0.263801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1073</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.256540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.217400</td>\n",
       "      <td>0.275888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1147</td>\n",
       "      <td>0.212400</td>\n",
       "      <td>0.252847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1184</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.253944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1221</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.252744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1258</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>0.255592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1295</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.238983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1332</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>0.257305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1369</td>\n",
       "      <td>0.192800</td>\n",
       "      <td>0.244152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1406</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.227911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1443</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.233025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.167900</td>\n",
       "      <td>0.228481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1517</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.234634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1554</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.224028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1591</td>\n",
       "      <td>0.164500</td>\n",
       "      <td>0.225827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1628</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.215567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1665</td>\n",
       "      <td>0.165100</td>\n",
       "      <td>0.219544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1702</td>\n",
       "      <td>0.162600</td>\n",
       "      <td>0.212800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1739</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.213344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>0.161300</td>\n",
       "      <td>0.212710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1813</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.217733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.153300</td>\n",
       "      <td>0.205762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1887</td>\n",
       "      <td>0.142400</td>\n",
       "      <td>0.210534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1924</td>\n",
       "      <td>0.138700</td>\n",
       "      <td>0.195996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1961</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>0.206907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>0.187027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2035</td>\n",
       "      <td>0.134500</td>\n",
       "      <td>0.195501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2072</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.194266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2109</td>\n",
       "      <td>0.124600</td>\n",
       "      <td>0.197700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2146</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.181131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2183</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>0.179860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.183246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2257</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.190041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2294</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.174519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2331</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.165443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2368</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.165544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2405</td>\n",
       "      <td>0.107100</td>\n",
       "      <td>0.158208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2442</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.158728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2479</td>\n",
       "      <td>0.117900</td>\n",
       "      <td>0.167369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2516</td>\n",
       "      <td>0.128100</td>\n",
       "      <td>0.162207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2553</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.152303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2590</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.136652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2627</td>\n",
       "      <td>0.120900</td>\n",
       "      <td>0.150579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.136109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2701</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.130422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2738</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>0.147791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2775</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.128962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2812</td>\n",
       "      <td>0.100700</td>\n",
       "      <td>0.128068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2849</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.118806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2886</td>\n",
       "      <td>0.097200</td>\n",
       "      <td>0.118468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2923</td>\n",
       "      <td>0.094800</td>\n",
       "      <td>0.137889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.130574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2997</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.103560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3034</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.108944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3071</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.116595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3108</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>0.106360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3145</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.101837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3182</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.105299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3219</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.111166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3256</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.093541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3293</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.095093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.084770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3367</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.086105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3404</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.079201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3441</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.088214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3478</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>0.091888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3515</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.087589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.087083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3589</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.073488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3626</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.089615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3663</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.083990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.100965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3737</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.083460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3774</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.076349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3811</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.085225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3848</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.077933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3885</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.092813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3922</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.084144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3959</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.071299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3996</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.073481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4033</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.068429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4070</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.070481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4107</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.077545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4144</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.077405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4181</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.070637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4218</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.099092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4255</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.068014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4292</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>0.072058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4329</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.062237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4366</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.062442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4403</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>0.063024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.058080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4477</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.061661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4514</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>0.064693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4551</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.056759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4588</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.063377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4625</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.053635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4662</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.077515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4699</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>0.066646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4736</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.060966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4773</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.053603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4810</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.293934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4847</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.119659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4884</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.095742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4921</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.083596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4958</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>0.074776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4995</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.075084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5032</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.071628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5069</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.079904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5106</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.071534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5143</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.072755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5180</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.063919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5217</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.058819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5254</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.053760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5291</td>\n",
       "      <td>0.046900</td>\n",
       "      <td>0.057966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.058834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5365</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.076807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5402</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.055338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5439</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.055984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5476</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.051630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5513</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.053126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5550</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.053162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5587</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>0.049159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5624</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.048924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5661</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.050273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5698</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.049045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5735</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.048080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5772</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.107708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5809</td>\n",
       "      <td>0.053400</td>\n",
       "      <td>0.058920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5846</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.059321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5883</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.049812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5920</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.050615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5957</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.052914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5994</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.056077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6031</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.055042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6068</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.053154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6105</td>\n",
       "      <td>0.051800</td>\n",
       "      <td>0.050285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6142</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.050601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6179</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.056268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.051315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6253</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.043130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6290</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.062429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6327</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>0.058385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6364</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.051692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6401</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.049873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6438</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.047509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6475</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.059032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6512</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.055320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6549</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>0.047755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6586</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.043228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6623</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.045219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6660</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.042329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6697</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.050311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6734</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>0.042913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6771</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.042289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6808</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>0.047200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6845</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.051716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6882</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.048848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6919</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.045964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6956</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.052114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6993</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.044340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7030</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.043674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7067</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.041256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.042642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7141</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.042534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7178</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>0.041159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7215</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.041175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7252</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.042127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7289</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.040174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7326</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.041753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7363</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.039622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.041225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7437</td>\n",
       "      <td>0.038600</td>\n",
       "      <td>0.040625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7474</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.046788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7511</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.040228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7548</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.040991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7585</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.037362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7622</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.041399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7659</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.046006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7696</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.043846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7733</td>\n",
       "      <td>0.101900</td>\n",
       "      <td>0.108697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7770</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.065644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7807</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.046802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7844</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.046893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7881</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.044658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7918</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.042676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7955</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.041402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.040617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8029</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.065366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8066</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.051717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8103</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>0.043400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8140</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.038398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8177</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.039238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8214</td>\n",
       "      <td>0.039300</td>\n",
       "      <td>0.040868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8251</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.039134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8288</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.045092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8325</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.039032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8362</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.040502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8399</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.036759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8436</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>0.037102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8473</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.040294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8510</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.040551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8547</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.037937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8584</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>0.040927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8621</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.048987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8658</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>0.037290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8695</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.039956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8732</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.042819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8769</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.038896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8806</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.036806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8843</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.055642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.107480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8917</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.064286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8954</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8991</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.043049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9028</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.038047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9065</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9102</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.035949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9139</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.036532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9176</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.037742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9213</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.041766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9250</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.036919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9287</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>0.036030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9324</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.037668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9361</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.036298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9398</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.041422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9435</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.039074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9472</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.035666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9509</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.034850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9546</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.036274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9583</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.039691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9620</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.038093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9657</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.036335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9694</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.036544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9731</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.039992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.036404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9805</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.041638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9842</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.036264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9879</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.038487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9916</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.039057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9953</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.045134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9990</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.043354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10027</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.041519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10064</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>0.047249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10101</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.043157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10138</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.038826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10175</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.037888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10212</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.036147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10249</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.037919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10286</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.036947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10323</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.036444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10360</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.057646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10397</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.037450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10434</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.034134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10471</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.039624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10508</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.036450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10545</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.036913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10582</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.035519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10619</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.036865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.038538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10693</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.036689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10730</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.058345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10767</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.057687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10804</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.042043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10841</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.038069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10878</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.036805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10915</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.040995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10952</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.039032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10989</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.035623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11026</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.035201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11063</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.035521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.036572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11100, training_loss=0.09293475997676183, metrics={'train_runtime': 43483.9443, 'train_samples_per_second': 2.042, 'train_steps_per_second': 0.255, 'total_flos': 0.0, 'train_loss': 0.09293475997676183, 'epoch': 100.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './FirstMultiModel/EEGART')\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from SLT_dataloader import SignalDataCollator, RandonMaskDataCollator,ART_AUG_RandonMaskDataCollator\n",
    "\n",
    "from tf_config import SLTConfig\n",
    "from tf_model import SLTModel, SLTModel_ver2,ART_AUG\n",
    "from datetime import datetime\n",
    "\n",
    "# 获取当前日期时间，并格式化为 YYYYMMDD\n",
    "current_date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# 替换路径中的日期\n",
    "runname = \"mask_prob_08_tgtwithoutEEG_learnable_position_\"\n",
    "output_dir = f\"G:\\\\共用雲端硬碟\\\\CNElab_專題111_ArtifactRemoval\\\\6.Opendataset\\\\0.Resting(train)\\\\2.rawdata\\\\test\\\\ART_output{runname}_{current_date}\"\n",
    "\n",
    "# 假設你的設備是 GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\"\"\"\n",
    "    Parameters:\n",
    "    \n",
    "\"\"\"\n",
    "# src_channel_size = 30\n",
    "# tgt_channel_size = 204\n",
    "# N = 4\n",
    "# source_voxel_time = 51\n",
    "# sensor_time = 51\n",
    "# tgt_d_model = 51\n",
    "# slt_config_fname = \"test_slt_confit\"\n",
    "\n",
    "# 包裝自定義的初始化方法\n",
    "def huggingface_model_init():\n",
    "    \n",
    "    src_len = 30\n",
    "    tgt_len = 30 # atlas size \n",
    "    N = 6\n",
    "    source_voxel_time = 101\n",
    "    sensor_time = 101\n",
    "    tgt_d_model = 128\n",
    "    slt_config_fname = \"test_slt_confit\"\n",
    "    \n",
    "    slt_config = SLTConfig(src_channel_size=src_len, tgt_channel_size=tgt_len, N=N,\n",
    "                           source_voxel_time=source_voxel_time, sensor_time=sensor_time, tgt_d_model=tgt_d_model)\n",
    "    slt_config.save_pretrained(slt_config_fname)\n",
    "    slt_model =ART_AUG(slt_config)       #SLTModel(slt_config)\n",
    "    slt_model = slt_model.to(device)\n",
    "    for p in slt_model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            torch.nn.init.xavier_uniform_(p)\n",
    "    return slt_model\n",
    "\n",
    "batch_size = 8\n",
    "train_data_len=(len(train_dataset))\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    run_name = runname,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=batch_size,   # training batch size\n",
    "    per_device_eval_batch_size=batch_size,    # test batch size\n",
    "    eval_steps= int((train_data_len/batch_size)/3),  # eval steps= 1/3 steps of one epoch\n",
    "    eval_accumulation_steps= 4,        \n",
    "    num_train_epochs=100,              # epoch\n",
    "    weight_decay=0.01,                 # \n",
    "    learning_rate = 0.0005,\n",
    "    lr_scheduler_type = \"constant\",\n",
    "    # fp16=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps= int((train_data_len/batch_size)/10),\n",
    "    report_to=\"none\", #\"wandb\",\n",
    "    dataloader_num_workers=8,  # 🚀 Use multiple workers\n",
    "    dataloader_pin_memory=True,# 🚀 Reduce CPU-GPU data transfer time\n",
    ")\n",
    "\n",
    "# def compute_metrics(eval_preds, batch_size=64):\n",
    "#     predictions, targets = eval_preds\n",
    "    \n",
    "#     loss_fct = nn.MSELoss()\n",
    "#     num_samples = predictions.shape[0]\n",
    "#     mse_sum = 0.0\n",
    "#     num_batches = 0\n",
    "\n",
    "#     for start_idx in range(0, num_samples, batch_size):\n",
    "#         end_idx = min(start_idx + batch_size, num_samples)\n",
    "#         logits_batch = predictions[start_idx:end_idx]\n",
    "#         labels_batch = targets[start_idx:end_idx]\n",
    "#         logits = torch.tensor(logits_batch, dtype=torch.float32)\n",
    "#         labels = torch.tensor(labels_batch, dtype=torch.float32)\n",
    "#         # Compute the z-scores for the batch\n",
    "#         logits_mean = torch.mean(logits, dim=(1, 2), keepdim=True)\n",
    "#         logits_std = torch.std(logits, dim=(1, 2), keepdim=True)\n",
    "#         logits_norm = (logits - logits_mean) / (logits_std)\n",
    "        \n",
    "#         labels_mean = torch.mean(labels, dim=(1, 2), keepdim=True)\n",
    "#         labels_std = torch.std(labels,  dim=(1, 2), keepdim=True)\n",
    "#         labels_norm = (labels - labels_mean) / (labels_std)\n",
    "        \n",
    "#         # Compute batch MSE\n",
    "#         mse_sum += loss_fct(logits_norm, labels_norm).item()\n",
    "#         num_batches += 1\n",
    "\n",
    "#     # Return the average MSE\n",
    "#     avg_mse = mse_sum / num_batches\n",
    "    \n",
    "#     del logits, labels, logits_norm, labels_norm\n",
    "#     torch.cuda.empty_cache()\n",
    "    \n",
    "#     return {\"mse\": avg_mse}\n",
    "\n",
    "def dummy_compute_metrics(eval_preds):\n",
    "    return {}  # Return empty dict\n",
    "\n",
    "# 初始化模型和 Trainer\n",
    "trainer = Trainer(\n",
    "    # model=slt_model,\n",
    "    model_init=huggingface_model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,     #merge_dataset,\n",
    "    eval_dataset=test_dataset,      #merge_eval_dataset,\n",
    "    data_collator=ART_AUG_RandonMaskDataCollator(mask_prob=0.55),\n",
    "    # compute_metrics=dummy_compute_metrics,\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
